import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import cv2
import pytesseract
import pandas as pd
import numpy as np
import time
import os
import av

st.set_page_config(page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ OCRï¼‹éŸ³å£°å†ç”Ÿï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰å®‰å®šç‰ˆï¼‰", layout="wide")

st.title("ðŸ“· ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ OCRï¼‹éŸ³å£°å†ç”Ÿï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰å®‰å®šç‰ˆï¼‰")

# -----------------------------
# OCRã¨éŸ³å£°ãƒžãƒƒãƒ”ãƒ³ã‚°
# -----------------------------
@st.cache_data
def load_mapping():
    df = pd.read_csv("mapping.csv")
    return {row["text"]: row["audio"] for _, row in df.iterrows()}

mapping = load_mapping()

# -----------------------------
# åˆæœŸè¨­å®š
# -----------------------------
st.sidebar.header("è¨­å®š")
interval = st.sidebar.slider("OCRã®æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰", 1.0, 5.0, 2.0, 0.5)

roi_x = st.sidebar.slider("ROI Xä½ç½®", 0, 100, 25)
roi_y = st.sidebar.slider("ROI Yä½ç½®", 0, 100, 25)
roi_w = st.sidebar.slider("ROI å¹…", 10, 100, 50)
roi_h = st.sidebar.slider("ROI é«˜ã•", 10, 100, 50)

# -----------------------------
# OCRå‡¦ç†é–¢æ•°
# -----------------------------
def process_frame(frame, last_ocr_time, prev_text):
    img = frame.to_ndarray(format="bgr24")
    h, w, _ = img.shape

    # ROIã‚’å‰²åˆã‹ã‚‰ç®—å‡º
    x1 = int(w * roi_x / 100)
    y1 = int(h * roi_y / 100)
    x2 = int(w * (roi_x + roi_w) / 100)
    y2 = int(h * (roi_y + roi_h) / 100)
    roi = img[y1:y2, x1:x2]

    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)

    now = time.time()
    text = prev_text

    # ä¸€å®šé–“éš”ã§OCR
    if now - last_ocr_time > interval:
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
        text = pytesseract.image_to_string(gray, lang="jpn+eng").strip()
        return img, text, now
    else:
        return img, prev_text, last_ocr_time


# -----------------------------
# ã‚¹ãƒˆãƒªãƒ¼ãƒ è¡¨ç¤º
# -----------------------------
st.write("ðŸŽ¥ ã‚«ãƒ¡ãƒ©æ˜ åƒãŒä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ï¼ˆROIæž å†…ã‚’èªè­˜ï¼‰")

webrtc_ctx = webrtc_streamer(
    key="ocr",
    mode=WebRtcMode.SENDRECV,
    video_frame_callback=None,
    media_stream_constraints={"video": True, "audio": False},
    async_processing=True,
)

# -----------------------------
# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆéŸ³å£°å†ç”Ÿãªã©ï¼‰
# -----------------------------
if webrtc_ctx.video_receiver:
    placeholder = st.empty()
    prev_text = ""
    last_ocr_time = 0
    last_sound_time = 0

    while webrtc_ctx.state.playing:
        frame = webrtc_ctx.video_receiver.get_frame(timeout=1)
        if frame is None:
            continue

        img, text, last_ocr_time = process_frame(frame, last_ocr_time, prev_text)
        prev_text = text

        # è¡¨ç¤º
        stframe = placeholder.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

        if text:
            st.write(f"ðŸ” èªè­˜çµæžœ: **{text}**")

            # CSVå¯¾å¿œéŸ³å£°ãŒã‚ã‚Œã°å†ç”Ÿ
            if text in mapping and time.time() - last_sound_time > interval:
                audio_path = os.path.join("sounds", mapping[text])
                if os.path.exists(audio_path):
                    st.audio(audio_path, format="audio/mp3")
                    last_sound_time = time.time()

        time.sleep(0.1)
