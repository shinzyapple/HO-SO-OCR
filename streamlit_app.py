import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
import easyocr
import pandas as pd
import cv2
import numpy as np
import threading
import time
import os

st.set_page_config(page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ OCRï¼‹éŸ³å£°å†ç”Ÿ", layout="wide")

st.title("ğŸ“· ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ OCRï¼‹éŸ³å£°å†ç”Ÿï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰å¯¾å¿œï¼‰")

# -----------------------------
# CSVèª­ã¿è¾¼ã¿ï¼ˆæ–‡å­—â†’éŸ³å£°å¯¾å¿œï¼‰
# -----------------------------
@st.cache_data
def load_mapping():
    df = pd.read_csv("mapping.csv")
    return {row["text"]: row["audio"] for _, row in df.iterrows()}

mapping = load_mapping()

# -----------------------------
# EasyOCRãƒ¢ãƒ‡ãƒ«èª­è¾¼
# -----------------------------
@st.cache_resource
def load_reader():
    return easyocr.Reader(['ja', 'en'])

reader = load_reader()

# -----------------------------
# OCRå‡¦ç†ã‚¯ãƒ©ã‚¹
# -----------------------------
class VideoProcessor(VideoProcessorBase):
    def __init__(self):
        self.prev_text = None
        self.last_play_time = 0
        self.delay = 5  # ç§’
        self.result_text = ""

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")

        # ROIæŒ‡å®šï¼ˆä¸­å¤®éƒ¨åˆ†ã‚’ä½¿ã†ï¼‰
        h, w, _ = img.shape
        roi = img[h//3:h*2//3, w//4:w*3//4]

        # OCRå®Ÿè¡Œ
        results = reader.readtext(roi, detail=0)

        # æ ã‚’æç”»
        cv2.rectangle(img, (w//4, h//3), (w*3//4, h*2//3), (0, 255, 0), 2)

        if results:
            text = results[0]
            self.result_text = text

            if text != self.prev_text and text in mapping:
                self.prev_text = text
                # ä¸€å®šæ™‚é–“å¾Œã«éŸ³å£°å†ç”Ÿï¼ˆst.audioã¯ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰å´ã§ï¼‰
                self.last_play_time = time.time()

        return av.VideoFrame.from_ndarray(img, format="bgr24")

# -----------------------------
# WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
# -----------------------------
webrtc_ctx = webrtc_streamer(
    key="realtime-ocr",
    mode=WebRtcMode.SENDRECV,
    video_processor_factory=VideoProcessor,
    media_stream_constraints={"video": True, "audio": False},
    async_processing=True,
)

# -----------------------------
# éŸ³å£°å†ç”Ÿéƒ¨åˆ†ï¼ˆStreamlitå´ï¼‰
# -----------------------------
if webrtc_ctx and webrtc_ctx.video_processor:
    vp = webrtc_ctx.video_processor
    placeholder = st.empty()

    while webrtc_ctx.state.playing:
        if vp.result_text and vp.prev_text == vp.result_text:
            detected_text = vp.result_text
            st.write(f"ğŸ” èªè­˜æ–‡å­—ï¼š**{detected_text}**")

            # ä¸€å®šæ™‚é–“å¾Œã«éŸ³å£°ã‚’å†ç”Ÿ
            if time.time() - vp.last_play_time > vp.delay:
                if detected_text in mapping:
                    audio_path = os.path.join("sounds", mapping[detected_text])
                    if os.path.exists(audio_path):
                        placeholder.audio(audio_path, format="audio/mp3")
                    else:
                        st.warning("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                vp.last_play_time = time.time() + 999  # äºŒé‡å†ç”Ÿé˜²æ­¢

        time.sleep(0.5)
